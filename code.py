  # Cancer-Prediction
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  
  from sklearn.impute import SimpleImputer
  from sklearn.preprocessing import OneHotEncoder
  from sklearn.preprocessing import MinMaxScaler
  
  from sklearn_pandas import DataFrameMapper
  from sklearn.compose import ColumnTransformer
  
  from sklearn.model_selection import train_test_split
  from sklearn.neighbors import KNeighborsClassifier
  from sklearn.pipeline import Pipeline
  
  import sklearn.metrics as skmet
  import pickle
  
  import warnings
  warnings.filterwarnings("ignore")
  
  cancerdata = pd.read_csv(r"C:\Users\puroh\OneDrive\Desktop\CANCER PREDICTION")
  
  # MySQL Database connection
  from sqlalchemy import create_engine
  
  # Creating engine which connect to MySQL
  user = 'user1' # user name
  pw = 'user1' # password
  db = 'cancer_db' # database
  
  # creating engine to connect database
  engine = create_engine(f"mysql+pymysql://{user}:{pw}@localhost/{db}")
  
  # dumping data into database 
  cancerdata.to_sql('cancer', con = engine, if_exists = 'replace', chunksize = 1000, index = False)
  
  # loading data from database
  sql = 'select * from cancer'
  
  cancerdf = pd.read_sql_query(sql, con = engine)
  
  # Data Preprocessing & EDA
  # Converting B to Benign and M to Malignant 
  cancerdf['diagnosis'] = np.where(cancerdf['diagnosis'] == 'B', 'Benign', cancerdf['diagnosis'])
  cancerdf['diagnosis'] = np.where(cancerdf['diagnosis'] == 'M', 'Malignant', cancerdf['diagnosis'])
  
  cancerdf.drop(['id'], axis = 1, inplace = True) # Excluding id column
  cancerdf.info()   # No missing values observed
  
  cancerdf.describe()
  
  # Seggretating input and output variables 
  cancerdf_X = pd.DataFrame(cancerdf.iloc[:, 1:])
  cancerdf_y = pd.DataFrame(cancerdf.iloc[:, 0])
  
  # EDA and Data Preparation
  cancerdf_X.info()
  
  # All numeric features
  numeric_features = cancerdf_X.select_dtypes(exclude = ['object']).columns
  
  numeric_features
  
  # Imputation strategy for numeric columns
  num_pipeline = Pipeline([('impute', SimpleImputer(strategy = 'mean'))])
  
  # All categorical features
  categorical_features = cancerdf_X.select_dtypes(include = ['object']).columns
  
  categorical_features 
  
  # DataFrameMapper is used to map the given Attribute
  # Encoding categorical to numeric variable
  categ_pipeline = Pipeline([('label', DataFrameMapper([(categorical_features, OneHotEncoder(drop = 'first'))]))])
  
  
  # Using ColumnTransformer to transform the columns of an array or Pandas DataFrame. 
  # This estimator allows different columns or column subsets of the input to be transformed separately and 
  # the features generated by each transformer will be concatenated to form a single feature space.
  preprocess_pipeline = ColumnTransformer([('categorical', categ_pipeline, categorical_features), 
                                         ('numerical', num_pipeline, numeric_features)])
  
  processed = preprocess_pipeline.fit(cancerdf_X)  # Fit the pipeline
  
  processed
  
  # Save the defined pipeline
  import joblib
  joblib.dump(processed, 'processed1')
  
  import os 
  os.getcwd()
  
  # Transform the original data using the pipeline defined above
  cancerclean = pd.DataFrame(processed.transform(cancerdf_X), columns = cancerdf_X.columns)  # Cleaned and processed data for ML Algorithm
  
  cancerclean.info()
  
  # Define scaling pipeline
  scale_pipeline = Pipeline([('scale', MinMaxScaler())])
  
  preprocess_pipeline2 = ColumnTransformer([('scale', scale_pipeline, cancerclean.columns)]) 
  
  processed2 = preprocess_pipeline2.fit(cancerclean)
  processed2
  
  # Save the Scaling pipeline
  joblib.dump(processed2, 'processed2')
  
  import os 
  os.getcwd()
  
  # Normalized data frame (considering the numerical part of data)
  cancerclean_n = pd.DataFrame(processed2.transform(cancerclean), columns = cancerclean.columns)
  
  eda = cancerclean_n.describe()
  eda
  # Split the data into training and testing sets
  X_train, X_test, y_train, y_test = train_test_split(cancerclean_n, cancerdf_y, test_size=0.2, random_state=42)
  
  # Train the K-Nearest Neighbors classifier
  knn = KNeighborsClassifier(n_neighbors=5)
  knn.fit(X_train, y_train)
  
  # Make predictions on the test set
  y_pred = knn.predict(X_test)
  
  # Evaluate the model
  accuracy = skmet.accuracy_score(y_test, y_pred)
  print("Accuracy:", accuracy)
  
  # Save the trained model
  filename = 'knn_model.sav'
  pickle.dump(knn, open(filename, 'wb'))
  
  # Load the saved model
  loaded_model = pickle.load(open(filename, 'rb'))
  
  # Make predictions using the loaded model
  y_pred_loaded = loaded_model.predict(X_test)
  
  # Compare the results with the original model
  print("Accuracy of loaded model:", skmet.accuracy_score(y_test, y_pred_loaded))

